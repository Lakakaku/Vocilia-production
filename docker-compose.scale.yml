version: '3.8'

services:
  # Load Balancer for Multi-Tenant Scale
  haproxy:
    image: haproxy:alpine
    ports:
      - "80:80"
      - "443:443"
      - "8404:8404"  # Stats page
    volumes:
      - ./scaling/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./scaling/ssl:/etc/ssl/certs:ro
      - haproxy_logs:/var/log
    depends_on:
      - api-gateway-1
      - api-gateway-2
      - business-dashboard-1
      - business-dashboard-2
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Redis Cluster for Multi-Tenant Caching
  redis-master:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_master_data:/data
      - ./scaling/redis-master.conf:/etc/redis/redis.conf:ro
    command: redis-server /etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  redis-replica-1:
    image: redis:7-alpine
    volumes:
      - redis_replica1_data:/data
      - ./scaling/redis-replica.conf:/etc/redis/redis.conf:ro
    command: redis-server /etc/redis/redis.conf --replicaof redis-master 6379
    depends_on:
      - redis-master
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  redis-replica-2:
    image: redis:7-alpine
    volumes:
      - redis_replica2_data:/data
      - ./scaling/redis-replica.conf:/etc/redis/redis.conf:ro
    command: redis-server /etc/redis/redis.conf --replicaof redis-master 6379
    depends_on:
      - redis-master
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # API Gateway Cluster
  api-gateway-1:
    build:
      context: .
      dockerfile: apps/api-gateway/Dockerfile
    environment:
      - NODE_ENV=production
      - INSTANCE_ID=api-gateway-1
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis-master:6379
      - REDIS_REPLICA_URLS=redis://redis-replica-1:6379,redis://redis-replica-2:6379
      - TENANT_MODE=multi
      - MAX_TENANTS=50
      - TENANT_ISOLATION=strict
    expose:
      - "3001"
    volumes:
      - app_logs:/app/logs
      - ./scaling/tenant-configs:/app/tenant-configs:ro
    depends_on:
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 15s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1"
        reservations:
          memory: 1G
          cpus: "0.5"

  api-gateway-2:
    build:
      context: .
      dockerfile: apps/api-gateway/Dockerfile
    environment:
      - NODE_ENV=production
      - INSTANCE_ID=api-gateway-2
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis-master:6379
      - REDIS_REPLICA_URLS=redis://redis-replica-1:6379,redis://redis-replica-2:6379
      - TENANT_MODE=multi
      - MAX_TENANTS=50
      - TENANT_ISOLATION=strict
    expose:
      - "3001"
    volumes:
      - app_logs:/app/logs
      - ./scaling/tenant-configs:/app/tenant-configs:ro
    depends_on:
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 15s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1"
        reservations:
          memory: 1G
          cpus: "0.5"

  # Business Dashboard Cluster (Analytics Optimized)
  business-dashboard-1:
    build:
      context: .
      dockerfile: apps/business-dashboard/Dockerfile.analytics
    environment:
      - NODE_ENV=production
      - INSTANCE_ID=business-dashboard-1
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - TENANT_MODE=multi
      - ANALYTICS_CACHE_SIZE=1024mb
      - ANALYTICS_WORKER_THREADS=6
    expose:
      - "3002"
    volumes:
      - business_analytics_cache:/app/analytics/cache
      - business_reports:/app/analytics/reports
    depends_on:
      - api-gateway-1
      - api-gateway-2
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3002/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 15s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.5"
        reservations:
          memory: 1.5G
          cpus: "0.75"

  business-dashboard-2:
    build:
      context: .
      dockerfile: apps/business-dashboard/Dockerfile.analytics
    environment:
      - NODE_ENV=production
      - INSTANCE_ID=business-dashboard-2
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - TENANT_MODE=multi
      - ANALYTICS_CACHE_SIZE=1024mb
      - ANALYTICS_WORKER_THREADS=6
    expose:
      - "3002"
    volumes:
      - business_analytics_cache:/app/analytics/cache
      - business_reports:/app/analytics/reports
    depends_on:
      - api-gateway-1
      - api-gateway-2
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3002/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 15s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.5"
        reservations:
          memory: 1.5G
          cpus: "0.75"

  # Customer PWA Auto-Scaling
  customer-pwa:
    build:
      context: .
      dockerfile: apps/customer-pwa/Dockerfile
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL}
      - TENANT_MODE=multi
    expose:
      - "3000"
    depends_on:
      - api-gateway-1
      - api-gateway-2
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 15s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

  # Dedicated Analytics Database (TimescaleDB)
  timescaledb:
    image: timescale/timescaledb:latest-pg14
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: analytics
      POSTGRES_USER: analytics_user
      POSTGRES_PASSWORD: ${ANALYTICS_DB_PASSWORD}
    volumes:
      - timescale_data:/var/lib/postgresql/data
      - ./scaling/analytics-init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U analytics_user -d analytics"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Analytics Processing Worker
  analytics-worker:
    build:
      context: .
      dockerfile: apps/analytics-worker/Dockerfile
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://redis-master:6379
      - ANALYTICS_DB_URL=postgresql://analytics_user:${ANALYTICS_DB_PASSWORD}@timescaledb:5432/analytics
      - WORKER_CONCURRENCY=4
      - BATCH_SIZE=1000
    volumes:
      - analytics_temp:/app/temp
      - business_reports:/app/reports
    depends_on:
      timescaledb:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3004/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1"
        reservations:
          memory: 512M
          cpus: "0.5"

  # Enhanced Prometheus for Multi-Tenant
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.scale.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/rules/multi-tenant:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=90d'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.wal-compression'
      - '--query.max-concurrency=50'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1"
        reservations:
          memory: 1G
          cpus: "0.5"

  # Multi-Tenant Grafana
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3100:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/multi-tenant:/etc/grafana/provisioning:ro
      - ./monitoring/dashboards/multi-tenant:/var/lib/grafana/dashboards:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_INSTALL_PLUGINS=redis-datasource,grafana-piechart-panel,grafana-clock-panel
      - GF_FEATURE_TOGGLES_ENABLE=publicDashboards
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  redis_master_data:
  redis_replica1_data:
  redis_replica2_data:
  timescale_data:
  business_analytics_cache:
  business_reports:
  analytics_temp:
  prometheus_data:
  grafana_data:
  app_logs:
  haproxy_logs:

networks:
  default:
    name: ai-feedback-scale
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Docker Swarm configuration for production scaling
x-deploy-defaults: &deploy-defaults
  restart_policy:
    condition: unless-stopped
    delay: 10s
    max_attempts: 3
    window: 120s
  update_config:
    parallelism: 1
    delay: 30s
    failure_action: rollback
    monitor: 60s
    max_failure_ratio: 0.2
  rollback_config:
    parallelism: 1
    delay: 10s
    failure_action: pause
    monitor: 60s
    max_failure_ratio: 0.2